"""
Google AI Studio service for spatial analysis, image understanding, and visualization
"""
import logging
import asyncio
import json
import base64
import aiohttp
import time
import mimetypes
from typing import Dict, List, Optional, Any, Tuple
from dataclasses import dataclass
from datetime import datetime, timedelta
from pathlib import Path
import io
from PIL import Image, ImageEnhance, ImageFilter
import numpy as np
from google import genai
from google.genai import types

from api.core.config import settings

logger = logging.getLogger(__name__)


@dataclass
class RoomAnalysis:
    """Results from room analysis"""
    room_type: str
    dimensions: Dict[str, float]
    lighting_conditions: str
    color_palette: List[str]
    existing_furniture: List[Dict[str, Any]]
    architectural_features: List[str]
    style_assessment: str
    confidence_score: float


@dataclass
class SpatialAnalysis:
    """Results from spatial analysis"""
    layout_type: str
    traffic_patterns: List[str]
    focal_points: List[Dict[str, Any]]
    available_spaces: List[Dict[str, Any]]
    placement_suggestions: List[Dict[str, Any]]
    scale_recommendations: Dict[str, Any]


@dataclass
class VisualizationRequest:
    """Request for room visualization"""
    base_image: str
    products_to_place: List[Dict[str, Any]]
    placement_positions: List[Dict[str, Any]]
    lighting_conditions: str
    render_quality: str
    style_consistency: bool
    user_style_description: str = ""  # User's actual text request


@dataclass
class VisualizationResult:
    """Result from visualization generation"""
    rendered_image: str
    processing_time: float
    quality_score: float
    placement_accuracy: float
    lighting_realism: float
    confidence_score: float


class GoogleAIStudioService:
    """Service for Google AI Studio integration"""

    def __init__(self):
        """Initialize Google AI Studio service"""
        self.api_key = settings.google_ai_api_key
        self.base_url = "https://generativelanguage.googleapis.com/v1beta"
        self.session = None
        self.rate_limiter = self._create_rate_limiter()
        self.usage_stats = {
            "total_requests": 0,
            "successful_requests": 0,
            "failed_requests": 0,
            "total_processing_time": 0.0,
            "last_reset": datetime.now()
        }

        self._validate_api_key()

        # Initialize new genai client for Gemini 2.5 Flash Image
        self.genai_client = genai.Client(api_key=self.api_key)

        # Debug: Log API key info (first 8 and last 4 characters for security)
        if len(self.api_key) > 12:
            masked_key = f"{self.api_key[:8]}...{self.api_key[-4:]}"
            logger.info(f"Google AI API Key loaded: {masked_key}")

        logger.info("Google AI Studio service initialized with Gemini 2.5 Flash Image support")

    def _validate_api_key(self):
        """Validate Google AI API key"""
        if not self.api_key:
            logger.error("Google AI Studio API key not configured")
            raise ValueError("Google AI Studio API key is required")

        logger.info("Google AI Studio API key validated")

    def _create_rate_limiter(self):
        """Create rate limiter for API calls"""
        class RateLimiter:
            def __init__(self, max_requests=30, time_window=60):
                self.max_requests = max_requests
                self.time_window = time_window
                self.requests = []

            async def acquire(self):
                now = datetime.now()
                # Remove old requests
                self.requests = [req for req in self.requests
                               if (now - req).total_seconds() < self.time_window]

                if len(self.requests) >= self.max_requests:
                    sleep_time = self.time_window - (now - self.requests[0]).total_seconds()
                    if sleep_time > 0:
                        await asyncio.sleep(sleep_time)

                self.requests.append(now)

        return RateLimiter()

    async def _get_session(self) -> aiohttp.ClientSession:
        """Get or create HTTP session"""
        if self.session is None:
            timeout = aiohttp.ClientTimeout(total=120)  # 2 minute timeout
            self.session = aiohttp.ClientSession(timeout=timeout)
        return self.session

    async def _make_api_request(self, endpoint: str, payload: Dict[str, Any]) -> Dict[str, Any]:
        """Make authenticated API request to Google AI Studio"""
        await self.rate_limiter.acquire()

        session = await self._get_session()
        url = f"{self.base_url}/{endpoint}"
        headers = {
            "Content-Type": "application/json",
            "x-goog-api-key": self.api_key
        }

        start_time = time.time()
        self.usage_stats["total_requests"] += 1

        try:
            async with session.post(url, json=payload, headers=headers) as response:
                if response.status == 200:
                    result = await response.json()
                    self.usage_stats["successful_requests"] += 1
                    processing_time = time.time() - start_time
                    self.usage_stats["total_processing_time"] += processing_time

                    logger.info(f"Google AI API request successful - Time: {processing_time:.2f}s")
                    return result
                else:
                    error_text = await response.text()
                    self.usage_stats["failed_requests"] += 1
                    logger.error(f"Google AI API error {response.status}: {error_text}")
                    raise Exception(f"API request failed: {response.status} - {error_text}")

        except Exception as e:
            self.usage_stats["failed_requests"] += 1
            logger.error(f"Google AI API request failed: {e}")
            raise

    async def analyze_room_image(self, image_data: str) -> RoomAnalysis:
        """Analyze room image for spatial understanding"""
        try:
            # Prepare image for analysis
            processed_image = self._preprocess_image(image_data)

            payload = {
                "contents": [{
                    "parts": [
                        {
                            "text": """Analyze this interior space image and provide detailed analysis in JSON format:

{
  "room_type": "living_room/bedroom/kitchen/etc",
  "dimensions": {
    "estimated_width_ft": 12.0,
    "estimated_length_ft": 15.0,
    "estimated_height_ft": 9.0,
    "square_footage": 180.0
  },
  "lighting_conditions": "natural/artificial/mixed",
  "color_palette": ["primary_color", "secondary_color", "accent_color"],
  "existing_furniture": [
    {
      "type": "sofa",
      "position": "center-left",
      "style": "modern",
      "color": "gray",
      "condition": "good"
    }
  ],
  "architectural_features": ["windows", "fireplace", "built_ins", "etc"],
  "style_assessment": "modern/traditional/transitional/etc",
  "layout_analysis": {
    "traffic_flow": "open/restricted/balanced",
    "focal_points": ["fireplace", "tv_wall", "window"],
    "available_floor_space": "adequate/limited/spacious"
  },
  "recommendations": {
    "lighting_improvements": ["add_table_lamps", "increase_natural_light"],
    "layout_suggestions": ["create_conversation_area", "improve_flow"],
    "style_opportunities": ["add_color", "introduce_texture"]
  }
}

Provide accurate measurements and detailed observations."""
                        },
                        {
                            "inline_data": {
                                "mime_type": "image/jpeg",
                                "data": processed_image
                            }
                        }
                    ]
                }],
                "generationConfig": {
                    "temperature": 0.3,
                    "topK": 40,
                    "topP": 0.95,
                    "maxOutputTokens": 2048,
                    "responseMimeType": "application/json"
                }
            }

            result = await self._make_api_request("models/gemini-1.5-pro:generateContent", payload)

            # Parse response
            content = result.get("candidates", [{}])[0].get("content", {})
            text_response = content.get("parts", [{}])[0].get("text", "{}")

            try:
                analysis_data = json.loads(text_response)
            except json.JSONDecodeError:
                logger.warning("Failed to parse JSON response, using fallback")
                analysis_data = self._create_fallback_room_analysis()

            return RoomAnalysis(
                room_type=analysis_data.get("room_type", "unknown"),
                dimensions=analysis_data.get("dimensions", {}),
                lighting_conditions=analysis_data.get("lighting_conditions", "mixed"),
                color_palette=analysis_data.get("color_palette", []),
                existing_furniture=analysis_data.get("existing_furniture", []),
                architectural_features=analysis_data.get("architectural_features", []),
                style_assessment=analysis_data.get("style_assessment", "unknown"),
                confidence_score=0.85  # High confidence for Google AI analysis
            )

        except Exception as e:
            logger.error(f"Error in room analysis: {e}")
            return self._create_fallback_room_analysis()

    async def perform_spatial_analysis(self, room_analysis: RoomAnalysis) -> SpatialAnalysis:
        """Perform spatial analysis for furniture placement"""
        try:
            # Create spatial analysis prompt
            spatial_prompt = f"""
Based on this room analysis, provide spatial layout recommendations:

Room Type: {room_analysis.room_type}
Dimensions: {room_analysis.dimensions}
Existing Furniture: {room_analysis.existing_furniture}
Architectural Features: {room_analysis.architectural_features}

Provide detailed spatial analysis in JSON format:
{{
  "layout_type": "open/closed/mixed",
  "traffic_patterns": ["main_walkway", "secondary_path"],
  "focal_points": [
    {{"type": "window", "position": "north_wall", "importance": "high"}},
    {{"type": "fireplace", "position": "east_wall", "importance": "medium"}}
  ],
  "available_spaces": [
    {{
      "area": "center_space",
      "dimensions": {{"width": 8, "length": 6}},
      "suitable_for": ["seating_group", "coffee_table"],
      "accessibility": "high"
    }}
  ],
  "placement_suggestions": [
    {{
      "furniture_type": "sofa",
      "recommended_position": "facing_fireplace",
      "distance_from_wall": 18,
      "orientation": "perpendicular_to_window",
      "reasoning": "creates_conversation_area"
    }}
  ],
  "scale_recommendations": {{
    "sofa_length": "84-96_inches",
    "coffee_table": "48x24_inches",
    "rug_size": "8x10_feet"
  }}
}}
"""

            payload = {
                "contents": [{
                    "parts": [{"text": spatial_prompt}]
                }],
                "generationConfig": {
                    "temperature": 0.2,
                    "maxOutputTokens": 1536,
                    "responseMimeType": "application/json"
                }
            }

            result = await self._make_api_request("models/gemini-1.5-pro:generateContent", payload)

            content = result.get("candidates", [{}])[0].get("content", {})
            text_response = content.get("parts", [{}])[0].get("text", "{}")

            try:
                spatial_data = json.loads(text_response)
            except json.JSONDecodeError:
                spatial_data = self._create_fallback_spatial_analysis()

            return SpatialAnalysis(
                layout_type=spatial_data.get("layout_type", "mixed"),
                traffic_patterns=spatial_data.get("traffic_patterns", []),
                focal_points=spatial_data.get("focal_points", []),
                available_spaces=spatial_data.get("available_spaces", []),
                placement_suggestions=spatial_data.get("placement_suggestions", []),
                scale_recommendations=spatial_data.get("scale_recommendations", {})
            )

        except Exception as e:
            logger.error(f"Error in spatial analysis: {e}")
            return self._create_fallback_spatial_analysis()

    async def detect_objects_in_room(self, image_data: str) -> List[Dict[str, Any]]:
        """Detect and classify objects in room image"""
        try:
            processed_image = self._preprocess_image(image_data)

            payload = {
                "contents": [{
                    "parts": [
                        {
                            "text": """Identify and locate all furniture and decor objects in this room image.

For each object, provide:
- Object type (sofa, chair, table, lamp, etc.)
- Position in room (left, center, right, foreground, background)
- Approximate size (small, medium, large)
- Style classification
- Color/material
- Condition assessment

Return results as JSON array:
[
  {
    "object_type": "sofa",
    "position": "center-left",
    "size": "large",
    "style": "modern",
    "color": "charcoal_gray",
    "material": "fabric",
    "condition": "good",
    "confidence": 0.95
  }
]"""
                        },
                        {
                            "inline_data": {
                                "mime_type": "image/jpeg",
                                "data": processed_image
                            }
                        }
                    ]
                }],
                "generationConfig": {
                    "temperature": 0.3,
                    "maxOutputTokens": 1024,
                    "responseMimeType": "application/json"
                }
            }

            result = await self._make_api_request("models/gemini-1.5-pro:generateContent", payload)

            content = result.get("candidates", [{}])[0].get("content", {})
            text_response = content.get("parts", [{}])[0].get("text", "[]")

            try:
                objects = json.loads(text_response)
                return objects if isinstance(objects, list) else []
            except json.JSONDecodeError:
                logger.warning("Failed to parse object detection response")
                return []

        except Exception as e:
            logger.error(f"Error in object detection: {e}")
            return []

    async def generate_room_visualization(self, visualization_request: VisualizationRequest) -> VisualizationResult:
        """Generate photorealistic room visualization using Gemini models with fallback"""
        try:
            start_time = time.time()

            # Prepare products description for the prompt
            products_description = []
            product_images = []
            for idx, product in enumerate(visualization_request.products_to_place):
                product_name = product.get('full_name') or product.get('name', 'furniture item')
                products_description.append(f"Product {idx+1}: {product_name}")

                # Download product image if available
                if product.get('image_url'):
                    try:
                        product_image_data = await self._download_image(product['image_url'])
                        if product_image_data:
                            product_images.append({
                                'data': product_image_data,
                                'name': product_name,
                                'index': idx + 1
                            })
                    except Exception as e:
                        logger.warning(f"Failed to download product image: {e}")

            # Process the base image
            processed_image = self._preprocess_image(visualization_request.base_image)

            # Use user's actual request as the primary directive
            user_request = visualization_request.user_style_description.strip()
            style_direction = ', '.join(products_description) if products_description else "modern, stylish furniture"

            # Build explicit product placement prompt with product images
            if products_description and product_images:
                products_list = '\n'.join([f"- {desc}" for desc in products_description])
                visualization_prompt = f"""âš ï¸ CRITICAL INSTRUCTION: THIS IS AN ADD-ONLY TASK, NOT A REDESIGN TASK âš ï¸

TASK: ADD the specific products listed below to EMPTY SPACES in this room. DO NOT change anything else.

PRODUCTS TO ADD (see reference images below):
{products_list}

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ðŸš« ABSOLUTELY FORBIDDEN - YOU MUST NOT DO THESE THINGS:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. âŒ DO NOT change wall colors, wall textures, or wall materials
2. âŒ DO NOT change flooring colors, patterns, or materials
3. âŒ DO NOT change ceiling color or design
4. âŒ DO NOT remove ANY existing furniture, even if it looks old or doesn't match
5. âŒ DO NOT replace ANY existing furniture or decor items
6. âŒ DO NOT move or reposition ANY existing furniture
7. âŒ DO NOT change the room's lighting, windows, or doors
8. âŒ DO NOT alter the room's style or color scheme
9. âŒ DO NOT add items that are NOT in the product list above
10. âŒ DO NOT redesign, transform, or makeover the room

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
âœ… THE ONLY THING YOU ARE ALLOWED TO DO:
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

1. âœ“ LOOK at the room image and IDENTIFY empty spaces (empty floor areas, empty sofa surfaces, empty tables, empty shelves, empty walls)
2. âœ“ LOOK at the product reference images to see exact colors, patterns, and designs
3. âœ“ ADD ONLY the products from the reference images to empty spaces
4. âœ“ MATCH the products EXACTLY to reference images (same color, pattern, texture, design)
5. âœ“ BLEND products naturally with realistic shadows and lighting

ðŸ“ WHERE TO PLACE PRODUCTS (only in EMPTY spaces):
- Throw pillows/cushions â†’ Empty spots on existing sofas, chairs, or beds
- Small furniture items â†’ Empty floor spaces (corners, empty walls)
- Decor items â†’ Empty surfaces on tables, shelves, or empty wall space
- Lamps/lighting â†’ Empty tables, empty floor corners

âš ï¸ IMPORTANT: If a sofa already has 3 pillows, you can add 1-2 MORE pillows. Do NOT remove the existing 3 pillows.
âš ï¸ IMPORTANT: If a room has a brown couch, keep the brown couch. Add new items around it or on it.

STYLE CONTEXT: {user_request if user_request else 'Place products naturally to complement the existing space'}

QUALITY REQUIREMENTS:
- Lighting: {visualization_request.lighting_conditions} - match the EXISTING lighting in the room
- Rendering: {visualization_request.render_quality} quality photorealism
- Product accuracy: EXACT match to reference images
- Shadows: Realistic shadows matching existing room lighting
- Perspective: Match the existing camera angle

â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
ðŸ” VERIFICATION CHECKLIST (check BEFORE generating):
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”

Before you generate the output image, verify:
âœ“ Same wall color and texture as input image?
âœ“ Same flooring as input image?
âœ“ Same ceiling as input image?
âœ“ ALL existing furniture still present (not removed)?
âœ“ ALL existing decor still present (not moved)?
âœ“ Same windows and doors?
âœ“ Same lighting setup?
âœ“ Only added products from the reference images?
âœ“ Added products look EXACTLY like reference images?
âœ“ Products placed in EMPTY spaces only?

If you answered NO to ANY of these questions, you MUST revise your output.

ðŸŽ¯ SUCCESS CRITERIA: The output must be the EXACT SAME ROOM with ONLY the new products added to empty spaces. A person looking at the before/after should say "Oh, they just added [product name] to my room!" NOT "Oh, they redesigned my entire room!"
            else:
                visualization_prompt = f"""Transform this interior space following this design request: {user_request}

Create a photorealistic interior design visualization that addresses the user's request while maintaining realistic proportions, lighting, and materials."""

            # Try multiple models in order of preference
            models_to_try = [
                ("gemini-2.5-flash-image", {"response_modalities": ["IMAGE", "TEXT"]})  # Primary image generation model
            ]

            transformed_image = None
            transformation_description = ""
            successful_model = None

            for model, config_params in models_to_try:
                try:
                    logger.info(f"Attempting image transformation with model: {model}")

                    # Build parts list with room image and all product images
                    parts = [types.Part.from_text(text=visualization_prompt)]

                    # Add room image
                    parts.append(types.Part(
                        inline_data=types.Blob(
                            mime_type="image/jpeg",
                            data=base64.b64decode(processed_image)
                        )
                    ))

                    # Add product images as references
                    for prod_img in product_images:
                        parts.append(types.Part.from_text(text=f"\nReference image for Product {prod_img['index']} ({prod_img['name']}):"))
                        parts.append(types.Part(
                            inline_data=types.Blob(
                                mime_type="image/jpeg",
                                data=base64.b64decode(prod_img['data'])
                            )
                        ))

                    contents = [
                        types.Content(
                            role="user",
                            parts=parts
                        ),
                    ]

                    generate_content_config = types.GenerateContentConfig(
                        **config_params,
                        temperature=0.4
                    )

                    # Stream response
                    for chunk in self.genai_client.models.generate_content_stream(
                        model=model,
                        contents=contents,
                        config=generate_content_config,
                    ):
                        if chunk.candidates is None or chunk.candidates[0].content is None or chunk.candidates[0].content.parts is None:
                            continue

                        for part in chunk.candidates[0].content.parts:
                            if part.inline_data and part.inline_data.data:
                                # Extract generated image data
                                inline_data = part.inline_data
                                image_bytes = inline_data.data
                                mime_type = inline_data.mime_type or "image/png"

                                # Convert to base64 data URI
                                image_base64 = base64.b64encode(image_bytes).decode('utf-8')
                                transformed_image = f"data:{mime_type};base64,{image_base64}"
                                logger.info(f"Successfully generated transformed image with {model} ({len(image_bytes)} bytes, {mime_type})")

                            elif part.text:
                                transformation_description += part.text

                    # If we got here without errors, mark as successful
                    successful_model = model
                    logger.info(f"Successfully used model: {model}")
                    break  # Exit the loop if successful

                except Exception as model_error:
                    logger.warning(f"Model {model} failed: {str(model_error)[:200]}")
                    # Continue to next model
                    continue

            processing_time = time.time() - start_time

            # If no image was generated, fall back to original
            if not transformed_image:
                logger.warning("No transformed image generated by any Gemini model, using original")
                transformed_image = visualization_request.base_image

            if transformation_description:
                logger.info(f"AI description: {transformation_description[:150]}...")

            if successful_model:
                logger.info(f"Generated visualization using {successful_model} with {len(products_description)} products in {processing_time:.2f}s")
            else:
                logger.error("All Gemini models failed, returning original image")

            return VisualizationResult(
                rendered_image=transformed_image,
                processing_time=processing_time,
                quality_score=0.92 if successful_model else 0.5,
                placement_accuracy=0.95 if successful_model else 0.0,
                lighting_realism=0.90 if successful_model else 0.0,
                confidence_score=0.93 if successful_model else 0.3
            )

        except Exception as e:
            logger.error(f"Error generating visualization: {e}", exc_info=True)
            # Return original image on error
            return VisualizationResult(
                rendered_image=visualization_request.base_image,
                processing_time=0.0,
                quality_score=0.5,
                placement_accuracy=0.0,
                lighting_realism=0.0,
                confidence_score=0.3
            )

    async def generate_text_based_visualization(
        self,
        base_image: str,
        user_request: str,
        lighting_conditions: str = "mixed",
        render_quality: str = "high"
    ) -> VisualizationResult:
        """
        Generate room visualization based on text description (allows full transformation)
        Used when user types text requesting image transformation (e.g., "make this modern")
        """
        try:
            start_time = time.time()

            # Process the base image
            processed_image = self._preprocess_image(base_image)

            # Build transformation prompt with strong room preservation
            visualization_prompt = f"""IMPORTANT: Use the EXACT room shown in this image as your base. Do NOT create a new room.

USER'S DESIGN REQUEST: {user_request}

ðŸ”’ CRITICAL PRESERVATION RULES:
1. USE THIS EXACT ROOM: Keep the same walls, windows, doors, flooring, ceiling, and architectural features shown in the image
2. PRESERVE THE SPACE: Maintain the exact room dimensions, layout, and perspective
3. KEEP EXISTING STRUCTURE: Do not change wall colors, window positions, door locations, or ceiling design unless specifically requested
4. SAME LIGHTING SETUP: Preserve existing light sources and natural lighting from windows

âœ¨ WHAT YOU CAN DO:
1. Add furniture and decor items as requested: {user_request}
2. Style the space according to user preferences while keeping the room structure
3. Place items naturally within THIS specific room layout
4. Ensure new items match the room's scale and perspective

QUALITY REQUIREMENTS:
- Lighting: {lighting_conditions} - match existing lighting in the image
- Rendering: {render_quality} quality photorealism
- Perspective: Maintain the exact camera angle and viewpoint from the input image

ðŸŽ¯ RESULT: The output must show THE SAME ROOM from the input image, just with design changes applied to furniture/decor."""

            # Use Gemini 2.5 Flash Image for generation
            model = "gemini-2.5-flash-image"
            parts = [
                types.Part.from_text(text=visualization_prompt),
                types.Part(
                    inline_data=types.Blob(
                        mime_type="image/jpeg",
                        data=base64.b64decode(processed_image)
                    )
                )
            ]

            contents = [types.Content(role="user", parts=parts)]
            generate_content_config = types.GenerateContentConfig(
                response_modalities=["IMAGE", "TEXT"],
                temperature=0.4
            )

            transformed_image = None
            transformation_description = ""

            # Stream response
            for chunk in self.genai_client.models.generate_content_stream(
                model=model,
                contents=contents,
                config=generate_content_config,
            ):
                if chunk.candidates is None or chunk.candidates[0].content is None or chunk.candidates[0].content.parts is None:
                    continue

                for part in chunk.candidates[0].content.parts:
                    if part.inline_data and part.inline_data.data:
                        # Extract generated image data
                        inline_data = part.inline_data
                        image_bytes = inline_data.data
                        mime_type = inline_data.mime_type or "image/png"

                        # Convert to base64 data URI
                        image_base64 = base64.b64encode(image_bytes).decode('utf-8')
                        transformed_image = f"data:{mime_type};base64,{image_base64}"
                        logger.info(f"Successfully generated text-based visualization ({len(image_bytes)} bytes)")

                    elif part.text:
                        transformation_description += part.text

            processing_time = time.time() - start_time

            # If no image was generated, fall back to original
            if not transformed_image:
                logger.warning("No transformed image generated, using original")
                transformed_image = base_image

            logger.info(f"Generated text-based visualization in {processing_time:.2f}s")

            return VisualizationResult(
                rendered_image=transformed_image,
                processing_time=processing_time,
                quality_score=0.90 if transformed_image != base_image else 0.5,
                placement_accuracy=0.85 if transformed_image != base_image else 0.0,
                lighting_realism=0.88 if transformed_image != base_image else 0.0,
                confidence_score=0.87 if transformed_image != base_image else 0.3
            )

        except Exception as e:
            logger.error(f"Error generating text-based visualization: {e}", exc_info=True)
            return VisualizationResult(
                rendered_image=base_image,
                processing_time=0.0,
                quality_score=0.5,
                placement_accuracy=0.0,
                lighting_realism=0.0,
                confidence_score=0.3
            )

    async def generate_iterative_visualization(
        self,
        base_image: str,
        modification_request: str,
        lighting_conditions: str = "mixed",
        render_quality: str = "high"
    ) -> VisualizationResult:
        """
        Generate iterative visualization by modifying an existing generated image
        Used when user requests changes to a previously generated visualization (e.g., "add more pillows")
        """
        try:
            start_time = time.time()

            # Process the base image (existing visualization)
            processed_image = self._preprocess_image(base_image)

            # Build iterative modification prompt with room preservation
            visualization_prompt = f"""IMPORTANT: This is the EXACT room to modify. Keep the same room structure, walls, windows, flooring, and perspective.

MODIFICATION REQUEST: {modification_request}

ðŸ”’ CRITICAL PRESERVATION RULES:
1. USE THIS EXACT ROOM: Keep the same walls, windows, doors, flooring, ceiling shown in this image
2. PRESERVE ROOM STRUCTURE: Do not change the room layout, dimensions, or architectural features
3. KEEP CAMERA ANGLE: Maintain the exact perspective and viewpoint
4. SAME BASE SPACE: This must remain the SAME physical room, just with the requested modification

âœ… APPLY ONLY THIS MODIFICATION:
- User request: {modification_request}
- Change ONLY what is specifically mentioned
- Keep ALL other elements exactly as shown
- If adding items, place them naturally in THIS room's existing layout

EXAMPLES OF CORRECT MODIFICATIONS:
- "add more pillows" â†’ Add 2-3 pillows to THIS room, matching existing decor, keep everything else identical
- "make it brighter" â†’ Increase lighting in THIS exact room, don't change furniture or layout
- "remove the lamp" â†’ Remove lamp from THIS room, keep all other items and room structure
- "add more of the same kind" â†’ Duplicate similar items visible in THIS image, in THIS same room

QUALITY REQUIREMENTS:
- Lighting: {lighting_conditions} - maintain existing light sources
- Rendering: {render_quality} quality photorealism
- Consistency: The room must look like the SAME physical space

ðŸŽ¯ RESULT: Output must show THIS EXACT ROOM with only the requested modification applied. Same walls, same windows, same floor, same perspective - just with the change requested."""

            # Use Gemini 2.5 Flash Image for generation
            model = "gemini-2.5-flash-image"
            parts = [
                types.Part.from_text(text=visualization_prompt),
                types.Part(
                    inline_data=types.Blob(
                        mime_type="image/jpeg",
                        data=base64.b64decode(processed_image)
                    )
                )
            ]

            contents = [types.Content(role="user", parts=parts)]
            generate_content_config = types.GenerateContentConfig(
                response_modalities=["IMAGE", "TEXT"],
                temperature=0.3  # Lower temperature for more consistent modifications
            )

            transformed_image = None
            transformation_description = ""

            # Stream response
            for chunk in self.genai_client.models.generate_content_stream(
                model=model,
                contents=contents,
                config=generate_content_config,
            ):
                if chunk.candidates is None or chunk.candidates[0].content is None or chunk.candidates[0].content.parts is None:
                    continue

                for part in chunk.candidates[0].content.parts:
                    if part.inline_data and part.inline_data.data:
                        # Extract generated image data
                        inline_data = part.inline_data
                        image_bytes = inline_data.data
                        mime_type = inline_data.mime_type or "image/png"

                        # Convert to base64 data URI
                        image_base64 = base64.b64encode(image_bytes).decode('utf-8')
                        transformed_image = f"data:{mime_type};base64,{image_base64}"
                        logger.info(f"Successfully generated iterative visualization ({len(image_bytes)} bytes)")

                    elif part.text:
                        transformation_description += part.text

            processing_time = time.time() - start_time

            # If no image was generated, fall back to original
            if not transformed_image:
                logger.warning("No modified image generated, using original")
                transformed_image = base_image

            logger.info(f"Generated iterative visualization in {processing_time:.2f}s")

            return VisualizationResult(
                rendered_image=transformed_image,
                processing_time=processing_time,
                quality_score=0.92 if transformed_image != base_image else 0.5,
                placement_accuracy=0.88 if transformed_image != base_image else 0.0,
                lighting_realism=0.90 if transformed_image != base_image else 0.0,
                confidence_score=0.89 if transformed_image != base_image else 0.3
            )

        except Exception as e:
            logger.error(f"Error generating iterative visualization: {e}", exc_info=True)
            return VisualizationResult(
                rendered_image=base_image,
                processing_time=0.0,
                quality_score=0.5,
                placement_accuracy=0.0,
                lighting_realism=0.0,
                confidence_score=0.3
            )

    async def _download_image(self, image_url: str) -> Optional[str]:
        """Download and preprocess product image from URL"""
        try:
            session = await self._get_session()
            async with session.get(image_url) as response:
                if response.status == 200:
                    image_bytes = await response.read()
                    image = Image.open(io.BytesIO(image_bytes))

                    # Convert to RGB
                    if image.mode != 'RGB':
                        image = image.convert('RGB')

                    # Resize for optimal processing (max 512px for product images)
                    max_size = 512
                    if image.width > max_size or image.height > max_size:
                        image.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)

                    # Convert to base64
                    buffer = io.BytesIO()
                    image.save(buffer, format='JPEG', quality=85, optimize=True)
                    return base64.b64encode(buffer.getvalue()).decode()
                else:
                    logger.warning(f"Failed to download image from {image_url}: {response.status}")
                    return None
        except Exception as e:
            logger.error(f"Error downloading image from {image_url}: {e}")
            return None

    def _preprocess_image(self, image_data: str) -> str:
        """Preprocess image for AI analysis"""
        try:
            # Remove data URL prefix if present
            if image_data.startswith('data:image'):
                image_data = image_data.split(',')[1]

            # Decode and process image
            image_bytes = base64.b64decode(image_data)
            image = Image.open(io.BytesIO(image_bytes))

            # Convert to RGB
            if image.mode != 'RGB':
                image = image.convert('RGB')

            # Resize for optimal processing (max 1024px)
            max_size = 1024
            if image.width > max_size or image.height > max_size:
                image.thumbnail((max_size, max_size), Image.Resampling.LANCZOS)

            # Enhance image quality
            enhancer = ImageEnhance.Sharpness(image)
            image = enhancer.enhance(1.1)

            # Convert back to base64
            buffer = io.BytesIO()
            image.save(buffer, format='JPEG', quality=90, optimize=True)
            return base64.b64encode(buffer.getvalue()).decode()

        except Exception as e:
            logger.error(f"Error preprocessing image: {e}")
            return image_data

    def _create_fallback_room_analysis(self) -> RoomAnalysis:
        """Create fallback room analysis"""
        return RoomAnalysis(
            room_type="living_room",
            dimensions={"estimated_width_ft": 12, "estimated_length_ft": 15, "square_footage": 180},
            lighting_conditions="mixed",
            color_palette=["neutral", "warm_gray", "white"],
            existing_furniture=[],
            architectural_features=["windows"],
            style_assessment="contemporary",
            confidence_score=0.3
        )

    def _create_fallback_spatial_analysis(self) -> SpatialAnalysis:
        """Create fallback spatial analysis"""
        return SpatialAnalysis(
            layout_type="open",
            traffic_patterns=["main_entrance_to_seating"],
            focal_points=[{"type": "window", "position": "main_wall", "importance": "high"}],
            available_spaces=[{"area": "center", "suitable_for": ["seating"], "accessibility": "high"}],
            placement_suggestions=[{"furniture_type": "sofa", "recommended_position": "facing_window"}],
            scale_recommendations={"sofa_length": "84_inches", "coffee_table": "48x24_inches"}
        )

    async def get_usage_statistics(self) -> Dict[str, Any]:
        """Get API usage statistics"""
        return {
            **self.usage_stats,
            "success_rate": (
                self.usage_stats["successful_requests"] /
                max(self.usage_stats["total_requests"], 1) * 100
            ),
            "average_processing_time": (
                self.usage_stats["total_processing_time"] /
                max(self.usage_stats["successful_requests"], 1)
            )
        }

    async def health_check(self) -> Dict[str, Any]:
        """Perform health check"""
        try:
            test_payload = {
                "contents": [{"parts": [{"text": "Test connection. Respond with 'OK'."}]}],
                "generationConfig": {"maxOutputTokens": 10}
            }

            start_time = time.time()
            await self._make_api_request("models/gemini-1.5-pro:generateContent", test_payload)
            response_time = time.time() - start_time

            return {
                "status": "healthy",
                "response_time": response_time,
                "api_key_valid": True,
                "usage_stats": await self.get_usage_statistics()
            }

        except Exception as e:
            return {
                "status": "unhealthy",
                "error": str(e),
                "api_key_valid": bool(self.api_key)
            }

    async def close(self):
        """Close HTTP session"""
        if self.session:
            await self.session.close()
            self.session = None


# Global service instance
google_ai_service = GoogleAIStudioService()